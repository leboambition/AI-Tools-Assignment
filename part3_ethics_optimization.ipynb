{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJ6LSz4YIknA",
        "outputId": "b9572186-6d30-45fd-deb5-98c356918ea5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ” ETHICAL AI ANALYSIS\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# Part 3: Ethics & Optimization\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "print(\"ğŸ” ETHICAL AI ANALYSIS\")\n",
        "print(\"=\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze potential biases in MNIST dataset\n",
        "print(\"ğŸ“Š MNIST MODEL BIAS ANALYSIS\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# Simulate potential bias scenarios (since we can't access raw MNIST metadata)\n",
        "print(\"\"\"\n",
        "Potential Biases in MNIST Model:\n",
        "\n",
        "1. **Writing Style Bias:**\n",
        "   - Most samples from North America/Europe\n",
        "   - Underrepresents Asian/Arabic numeral styles\n",
        "   - Cultural variations in handwriting not captured\n",
        "\n",
        "2. **Demographic Bias:**\n",
        "   - Collected from specific demographic groups (students, researchers)\n",
        "   - Age, education level, and cultural background not diverse\n",
        "\n",
        "3. **Data Collection Bias:**\n",
        "   - Clean, centered images vs. real-world messy handwriting\n",
        "   - Limited stroke width and pressure variations\n",
        "\n",
        "4. **Performance Disparities:**\n",
        "   - May perform poorly on digits with unusual strokes\n",
        "   - Could struggle with slanted or rotated writing\n",
        "\"\"\")\n",
        "\n",
        "# Simulate fairness metrics (in real scenario, use TensorFlow Fairness Indicators)\n",
        "print(\"\\nğŸ›¡ï¸ MITIGATION STRATEGIES for MNIST:\")\n",
        "print(\"\"\"\n",
        "- **Data Augmentation:** Rotate, skew, add noise to training data\n",
        "- **Diverse Data Collection:** Collect digits from global populations\n",
        "- **Fairness Testing:** Use tools like TensorFlow Fairness Indicators\n",
        "- **Regular Audits:** Monitor performance across different writing styles\n",
        "- **Transfer Learning:** Fine-tune on diverse handwriting datasets\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75xo7ZOmJCUb",
        "outputId": "05fa1b7d-91bd-4143-9e38-285a353dde17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“Š MNIST MODEL BIAS ANALYSIS\n",
            "========================================\n",
            "\n",
            "Potential Biases in MNIST Model:\n",
            "\n",
            "1. **Writing Style Bias:**\n",
            "   - Most samples from North America/Europe\n",
            "   - Underrepresents Asian/Arabic numeral styles\n",
            "   - Cultural variations in handwriting not captured\n",
            "\n",
            "2. **Demographic Bias:**\n",
            "   - Collected from specific demographic groups (students, researchers)\n",
            "   - Age, education level, and cultural background not diverse\n",
            "\n",
            "3. **Data Collection Bias:**\n",
            "   - Clean, centered images vs. real-world messy handwriting\n",
            "   - Limited stroke width and pressure variations\n",
            "\n",
            "4. **Performance Disparities:**\n",
            "   - May perform poorly on digits with unusual strokes\n",
            "   - Could struggle with slanted or rotated writing\n",
            "\n",
            "\n",
            "ğŸ›¡ï¸ MITIGATION STRATEGIES for MNIST:\n",
            "\n",
            "- **Data Augmentation:** Rotate, skew, add noise to training data\n",
            "- **Diverse Data Collection:** Collect digits from global populations  \n",
            "- **Fairness Testing:** Use tools like TensorFlow Fairness Indicators\n",
            "- **Regular Audits:** Monitor performance across different writing styles\n",
            "- **Transfer Learning:** Fine-tune on diverse handwriting datasets\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze potential biases in our sentiment analysis\n",
        "print(\"\\nğŸ˜Š AMAZON REVIEWS SENTIMENT ANALYSIS BIAS\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "print(\"\"\"\n",
        "Potential Biases in Review Analysis:\n",
        "\n",
        "1. **Language & Cultural Bias:**\n",
        "   - Only analyzed English reviews\n",
        "   - Cultural expressions of satisfaction vary globally\n",
        "   - Sarcasm and irony not properly handled\n",
        "\n",
        "2. **Product Category Bias:**\n",
        "   - Electronics-heavy sample data\n",
        "   - Underrepresents books, clothing, home goods\n",
        "   - Price point bias (mostly premium products)\n",
        "\n",
        "3. **Demographic Bias:**\n",
        "   - Reviews from tech-savvy users overrepresented\n",
        "   - Age, income, and geographic biases in reviewers\n",
        "\n",
        "4. **Rule-Based Limitations:**\n",
        "   - Simple keyword matching misses context\n",
        "   - \"Expensive\" can be negative (complaint) or positive (luxury)\n",
        "   - No understanding of comparative statements\n",
        "\"\"\")\n",
        "\n",
        "print(\"\\nğŸ›¡ï¸ MITIGATION STRATEGIES for Reviews:\")\n",
        "print(\"\"\"\n",
        "- **Multilingual Models:** Use spaCy models for different languages\n",
        "- **Context-Aware Analysis:** Implement transformer models for better understanding\n",
        "- **Diverse Training Data:** Include reviews from various product categories\n",
        "- **Bias Detection Tools:** Use spaCy's rule-based systems to flag potential biases\n",
        "- **Human-in-the-Loop:** Manual review of edge cases and ambiguous sentiments\n",
        "- **Regular Model Updates:** Continuously retrain on new, diverse data\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqWw5w8EJENT",
        "outputId": "f7ab90f9-4558-4e4f-b59e-ad4790b33118"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ˜Š AMAZON REVIEWS SENTIMENT ANALYSIS BIAS\n",
            "==================================================\n",
            "\n",
            "Potential Biases in Review Analysis:\n",
            "\n",
            "1. **Language & Cultural Bias:**\n",
            "   - Only analyzed English reviews\n",
            "   - Cultural expressions of satisfaction vary globally\n",
            "   - Sarcasm and irony not properly handled\n",
            "\n",
            "2. **Product Category Bias:**\n",
            "   - Electronics-heavy sample data\n",
            "   - Underrepresents books, clothing, home goods\n",
            "   - Price point bias (mostly premium products)\n",
            "\n",
            "3. **Demographic Bias:**\n",
            "   - Reviews from tech-savvy users overrepresented\n",
            "   - Age, income, and geographic biases in reviewers\n",
            "\n",
            "4. **Rule-Based Limitations:**\n",
            "   - Simple keyword matching misses context\n",
            "   - \"Expensive\" can be negative (complaint) or positive (luxury)\n",
            "   - No understanding of comparative statements\n",
            "\n",
            "\n",
            "ğŸ›¡ï¸ MITIGATION STRATEGIES for Reviews:\n",
            "\n",
            "- **Multilingual Models:** Use spaCy models for different languages\n",
            "- **Context-Aware Analysis:** Implement transformer models for better understanding\n",
            "- **Diverse Training Data:** Include reviews from various product categories\n",
            "- **Bias Detection Tools:** Use spaCy's rule-based systems to flag potential biases\n",
            "- **Human-in-the-Loop:** Manual review of edge cases and ambiguous sentiments\n",
            "- **Regular Model Updates:** Continuously retrain on new, diverse data\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Demonstrate spaCy rule-based bias mitigation\n",
        "print(\"\\nğŸ”§ SPACY RULE-BASED BIAS MITIGATION EXAMPLE\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "import spacy\n",
        "\n",
        "# Load spaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Create custom rules for bias detection\n",
        "bias_patterns = [\n",
        "    {\"label\": \"GENDER_BIAS\", \"pattern\": [{\"LOWER\": \"female\"}, {\"LOWER\": \"drivers\"}]},\n",
        "    {\"label\": \"GENDER_BIAS\", \"pattern\": [{\"LOWER\": \"male\"}, {\"LOWER\": \"nurse\"}]},\n",
        "    {\"label\": \"AGE_BIAS\", \"pattern\": [{\"LOWER\": \"old\"}, {\"LOWER\": \"technology\"}]},\n",
        "    {\"label\": \"CULTURAL_BIAS\", \"pattern\": [{\"LOWER\": \"foreign\"}, {\"LOWER\": \"products\"}]}\n",
        "]\n",
        "\n",
        "# Add patterns to entity ruler\n",
        "ruler = nlp.add_pipe(\"entity_ruler\", before=\"ner\")\n",
        "ruler.add_patterns(bias_patterns)\n",
        "\n",
        "# Test bias detection\n",
        "test_texts = [\n",
        "    \"Female drivers are less skilled according to this review\",\n",
        "    \"This old technology is unreliable\",\n",
        "    \"Foreign products have poor quality control\",\n",
        "    \"Male nurses are unusual in this hospital\"\n",
        "]\n",
        "\n",
        "print(\"Testing bias detection in sample texts:\")\n",
        "for text in test_texts:\n",
        "    doc = nlp(text)\n",
        "    print(f\"\\nğŸ“ Text: {text}\")\n",
        "    biases = [ent for ent in doc.ents if ent.label_ in [\"GENDER_BIAS\", \"AGE_BIAS\", \"CULTURAL_BIAS\"]]\n",
        "    if biases:\n",
        "        for bias in biases:\n",
        "            print(f\"   âš ï¸  POTENTIAL BIAS DETECTED: {bias.text} â†’ {bias.label_}\")\n",
        "    else:\n",
        "        print(\"   âœ… No biases detected\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YALkiWLDJJq8",
        "outputId": "6aa4afc8-bcc1-40ad-8a9f-c7b9cc1d39ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ”§ SPACY RULE-BASED BIAS MITIGATION EXAMPLE\n",
            "==================================================\n",
            "Testing bias detection in sample texts:\n",
            "\n",
            "ğŸ“ Text: Female drivers are less skilled according to this review\n",
            "   âš ï¸  POTENTIAL BIAS DETECTED: Female drivers â†’ GENDER_BIAS\n",
            "\n",
            "ğŸ“ Text: This old technology is unreliable\n",
            "   âš ï¸  POTENTIAL BIAS DETECTED: old technology â†’ AGE_BIAS\n",
            "\n",
            "ğŸ“ Text: Foreign products have poor quality control\n",
            "   âš ï¸  POTENTIAL BIAS DETECTED: Foreign products â†’ CULTURAL_BIAS\n",
            "\n",
            "ğŸ“ Text: Male nurses are unusual in this hospital\n",
            "   âœ… No biases detected\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nğŸ› TROUBLESHOOTING CHALLENGE: DEBUGGING CODE\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Provided buggy TensorFlow code (with intentional errors)\n",
        "print(\"\"\"\n",
        "ORIGINAL BUGGY CODE:\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28)),\n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\"\"\")\n",
        "\n",
        "# Debugged version\n",
        "print(\"\\nğŸ”§ DEBUGGED AND FIXED CODE:\")\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "print(\"\"\"\n",
        "# FIX 1: Input shape should include channel dimension\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),  # Added channel\n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# FIX 2: Use correct loss function for multi-class classification\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',  # Changed from binary_crossentropy\n",
        "              metrics=['accuracy'])\n",
        "\"\"\")\n",
        "\n",
        "print(\"\\nğŸ› BUGS IDENTIFIED AND FIXED:\")\n",
        "print(\"1. âŒ Dimension mismatch: input_shape missing channel dimension\")\n",
        "print(\"2. âŒ Incorrect loss function: binary_crossentropy for multi-class problem\")\n",
        "print(\"3. âœ… Fixed: Added channel to input_shape\")\n",
        "print(\"4. âœ… Fixed: Changed to categorical_crossentropy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FahVk3SsJP4x",
        "outputId": "cfd3f109-daa3-402a-fac7-f8cbfc535275"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ› TROUBLESHOOTING CHALLENGE: DEBUGGING CODE\n",
            "==================================================\n",
            "\n",
            "ORIGINAL BUGGY CODE:\n",
            "\n",
            "model = tf.keras.Sequential([\n",
            "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28)),\n",
            "    tf.keras.layers.MaxPooling2D((2,2)),\n",
            "    tf.keras.layers.Flatten(),\n",
            "    tf.keras.layers.Dense(128, activation='relu'),\n",
            "    tf.keras.layers.Dense(10, activation='softmax')\n",
            "])\n",
            "\n",
            "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
            "\n",
            "\n",
            "ğŸ”§ DEBUGGED AND FIXED CODE:\n",
            "\n",
            "# FIX 1: Input shape should include channel dimension\n",
            "model = tf.keras.Sequential([\n",
            "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),  # Added channel\n",
            "    tf.keras.layers.MaxPooling2D((2,2)),\n",
            "    tf.keras.layers.Flatten(),\n",
            "    tf.keras.layers.Dense(128, activation='relu'),\n",
            "    tf.keras.layers.Dense(10, activation='softmax')\n",
            "])\n",
            "\n",
            "# FIX 2: Use correct loss function for multi-class classification\n",
            "model.compile(optimizer='adam', \n",
            "              loss='categorical_crossentropy',  # Changed from binary_crossentropy\n",
            "              metrics=['accuracy'])\n",
            "\n",
            "\n",
            "ğŸ› BUGS IDENTIFIED AND FIXED:\n",
            "1. âŒ Dimension mismatch: input_shape missing channel dimension\n",
            "2. âŒ Incorrect loss function: binary_crossentropy for multi-class problem\n",
            "3. âœ… Fixed: Added channel to input_shape\n",
            "4. âœ… Fixed: Changed to categorical_crossentropy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's actually run the debugging exercise\n",
        "print(\"\\nğŸ› ï¸ PRACTICAL DEBUGGING EXERCISE\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# Create a simple working example to demonstrate the fix\n",
        "import numpy as np\n",
        "\n",
        "# Generate sample data\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Preprocess data correctly\n",
        "X_train = X_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
        "X_test = X_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
        "y_train_categorical = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test_categorical = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "# Build corrected model\n",
        "corrected_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "corrected_model.compile(optimizer='adam',\n",
        "                       loss='categorical_crossentropy',\n",
        "                       metrics=['accuracy'])\n",
        "\n",
        "print(\"âœ… CORRECTED MODEL SUMMARY:\")\n",
        "corrected_model.summary()\n",
        "\n",
        "# Quick test to verify it works\n",
        "print(\"\\nğŸ§ª QUICK VERIFICATION (2 epochs):\")\n",
        "history = corrected_model.fit(X_train[:1000], y_train_categorical[:1000],\n",
        "                             epochs=2, batch_size=32, verbose=1,\n",
        "                             validation_split=0.2)\n",
        "\n",
        "test_loss, test_accuracy = corrected_model.evaluate(X_test[:100], y_test_categorical[:100], verbose=0)\n",
        "print(f\"âœ… Debugging successful! Test accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "hVQfuFzaJTuz",
        "outputId": "7bd93a5b-6fb9-45ec-ea1d-2e7cc7d5e02e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ› ï¸ PRACTICAL DEBUGGING EXERCISE\n",
            "========================================\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… CORRECTED MODEL SUMMARY:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     â”‚           \u001b[38;5;34m320\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)     â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten (\u001b[38;5;33mFlatten\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5408\u001b[0m)           â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚       \u001b[38;5;34m692,352\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             â”‚         \u001b[38;5;34m1,290\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5408</span>)           â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">692,352</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m693,962\u001b[0m (2.65 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">693,962</span> (2.65 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m693,962\u001b[0m (2.65 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">693,962</span> (2.65 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ§ª QUICK VERIFICATION (2 epochs):\n",
            "Epoch 1/2\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.5357 - loss: 1.7287 - val_accuracy: 0.8150 - val_loss: 0.6462\n",
            "Epoch 2/2\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8603 - loss: 0.4552 - val_accuracy: 0.8400 - val_loss: 0.6121\n",
            "âœ… Debugging successful! Test accuracy: 0.8600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nğŸ“ ETHICAL REFLECTION SUMMARY\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "ethical_insights = \"\"\"\n",
        "KEY ETHICAL INSIGHTS FROM OUR AI DEVELOPMENT:\n",
        "\n",
        "ğŸ” **Bias Awareness:**\n",
        "   - Even \"simple\" datasets like MNIST contain hidden biases\n",
        "   - Cultural, demographic, and collection biases are pervasive\n",
        "   - Rule-based systems can amplify existing stereotypes\n",
        "\n",
        "ğŸ›¡ï¸ **Mitigation Strategies Implemented:**\n",
        "   - Data augmentation for diversity\n",
        "   - Multiple model validation techniques\n",
        "   - Rule-based bias detection with spaCy\n",
        "   - Proper loss functions and architecture choices\n",
        "\n",
        "ğŸš¨ **Continuous Monitoring Needed:**\n",
        "   - Regular fairness audits\n",
        "   - Diverse test case development\n",
        "   - Stakeholder feedback incorporation\n",
        "   - Transparency in model limitations\n",
        "\n",
        "ğŸŒ **Real-World Impact Considerations:**\n",
        "   - MNIST: Handwriting recognition systems used in postal, banking, education\n",
        "   - Sentiment Analysis: Influences product recommendations and business decisions\n",
        "   - Responsibility: Our models could affect real people and businesses\n",
        "\n",
        "âœ… **Best Practices Demonstrated:**\n",
        "   - Proper error handling and debugging\n",
        "   - Documentation of limitations\n",
        "   - Consideration of edge cases\n",
        "   - Ethical analysis alongside technical implementation\n",
        "\"\"\"\n",
        "\n",
        "print(ethical_insights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJcgQXh_JX8n",
        "outputId": "3087d88c-a78c-403a-df50-d98eaaea31a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“ ETHICAL REFLECTION SUMMARY\n",
            "==================================================\n",
            "\n",
            "KEY ETHICAL INSIGHTS FROM OUR AI DEVELOPMENT:\n",
            "\n",
            "ğŸ” **Bias Awareness:**\n",
            "   - Even \"simple\" datasets like MNIST contain hidden biases\n",
            "   - Cultural, demographic, and collection biases are pervasive\n",
            "   - Rule-based systems can amplify existing stereotypes\n",
            "\n",
            "ğŸ›¡ï¸ **Mitigation Strategies Implemented:**\n",
            "   - Data augmentation for diversity\n",
            "   - Multiple model validation techniques  \n",
            "   - Rule-based bias detection with spaCy\n",
            "   - Proper loss functions and architecture choices\n",
            "\n",
            "ğŸš¨ **Continuous Monitoring Needed:**\n",
            "   - Regular fairness audits\n",
            "   - Diverse test case development\n",
            "   - Stakeholder feedback incorporation\n",
            "   - Transparency in model limitations\n",
            "\n",
            "ğŸŒ **Real-World Impact Considerations:**\n",
            "   - MNIST: Handwriting recognition systems used in postal, banking, education\n",
            "   - Sentiment Analysis: Influences product recommendations and business decisions\n",
            "   - Responsibility: Our models could affect real people and businesses\n",
            "\n",
            "âœ… **Best Practices Demonstrated:**\n",
            "   - Proper error handling and debugging\n",
            "   - Documentation of limitations\n",
            "   - Consideration of edge cases\n",
            "   - Ethical analysis alongside technical implementation\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nâš¡ OPTIMIZATION BEST PRACTICES\")\n",
        "print(\"=\" * 45)\n",
        "\n",
        "optimization_tips = \"\"\"\n",
        "PERFORMANCE & OPTIMIZATION TIPS DEMONSTRATED:\n",
        "\n",
        "ğŸ¯ **Model Architecture:**\n",
        "   - Appropriate layer dimensions and types\n",
        "   - Correct loss functions for problem type\n",
        "   - Proper input shape handling\n",
        "\n",
        "ğŸš€ **Training Efficiency:**\n",
        "   - GPU utilization (T4 acceleration)\n",
        "   - Batch size optimization\n",
        "   - Early stopping and callbacks\n",
        "\n",
        "ğŸ”§ **Code Quality:**\n",
        "   - Debugging and error resolution\n",
        "   - Proper data preprocessing\n",
        "   - Efficient memory usage\n",
        "\n",
        "ğŸ“Š **Evaluation Rigor:**\n",
        "   - Multiple metric tracking\n",
        "   - Validation set usage\n",
        "   - Confusion matrix analysis\n",
        "   - Cross-validation where appropriate\n",
        "\n",
        "ğŸ”„ **Iterative Improvement:**\n",
        "   - Start simple, then complexify\n",
        "   - Regular testing and validation\n",
        "   - Performance benchmarking\n",
        "\"\"\"\n",
        "\n",
        "print(optimization_tips)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pNhQD6mJbcn",
        "outputId": "31c5bfd7-2395-4ffd-c32f-6cfd6201a8cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âš¡ OPTIMIZATION BEST PRACTICES\n",
            "=============================================\n",
            "\n",
            "PERFORMANCE & OPTIMIZATION TIPS DEMONSTRATED:\n",
            "\n",
            "ğŸ¯ **Model Architecture:**\n",
            "   - Appropriate layer dimensions and types\n",
            "   - Correct loss functions for problem type\n",
            "   - Proper input shape handling\n",
            "\n",
            "ğŸš€ **Training Efficiency:**\n",
            "   - GPU utilization (T4 acceleration)\n",
            "   - Batch size optimization\n",
            "   - Early stopping and callbacks\n",
            "\n",
            "ğŸ”§ **Code Quality:**\n",
            "   - Debugging and error resolution\n",
            "   - Proper data preprocessing\n",
            "   - Efficient memory usage\n",
            "\n",
            "ğŸ“Š **Evaluation Rigor:**\n",
            "   - Multiple metric tracking\n",
            "   - Validation set usage\n",
            "   - Confusion matrix analysis\n",
            "   - Cross-validation where appropriate\n",
            "\n",
            "ğŸ”„ **Iterative Improvement:**\n",
            "   - Start simple, then complexify\n",
            "   - Regular testing and validation\n",
            "   - Performance benchmarking\n",
            "\n"
          ]
        }
      ]
    }
  ]
}